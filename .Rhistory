# Chunk 4
df1 <- df1[,-c(1,3)]
# Chunk 5
set.seed(9850)
# Chunk 6
gp <- runif(nrow(df1))
# Chunk 7
df1_KNN <- df1[order(gp),]
# Chunk 8
normalize <- function(x){
return( (x - min(x)) / (max(x) - min(x)))}
# Chunk 9
df1_KNN_n <- as.data.frame(lapply(df1_KNN[,c(2,3,4,5,6,7,8,9,10)], normalize))
# Chunk 10
df1_KNN_train <- df1_KNN_n[1:552, ]
df1_KNN_test <- df1_KNN_n[553:735, ]
df1_KNN_train_target <- df1_KNN[1:552, 12]
df1_KNN_test_target <- df1_KNN[553:735, 12]
# Chunk 11
m1 <- knn(train = df1_KNN_train, test = df1_KNN_test, cl = df1_KNN_train_target, k=11, prob = TRUE)
# Chunk 12
confusionMatrix(m1, df1_KNN_test_target)
# Chunk 13
knn_confusion <- as.data.frame(table(df1_KNN_test_target, m1))
knn_plot <- ggplot(knn_confusion)
knn_plot + geom_tile(aes(x=df1_KNN_test_target, y=m1, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "KNN Confusion Matrix") + geom_text(data = knn_confusion, aes(x=df1_KNN_test_target, y=m1, label=Freq), color = "white")
# Chunk 14
knn_prob <- attr(m1, "prob")
# Chunk 15
prob <- 2*ifelse(m1 == "-1", 1-knn_prob, knn_prob) - 1
# Chunk 16
pred_knn <- prediction(knn_prob, df1_KNN_test_target)
# Chunk 17
pred_knn <- performance(pred_knn, "tpr", "fpr")
# Chunk 18
area <- auc(df1_KNN_test_target, knn_prob)
# Chunk 19
rocplot <- function(knn_prob, df1_KNN_test_target, ...) {
predob = prediction(knn_prob, df1_KNN_test_target)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(knn_prob, df1_KNN_test_target, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
# Chunk 4
df1 <- df1[,-c(1,2,3,13)]
# Chunk 5
gp <- runif(nrow(df1))
# Chunk 6
df1 <- df1[order(gp),]
# Chunk 7
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
# Chunk 8
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
# Chunk 9
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Chunk 10
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .15, 0.30),
C = c(0.01, 0.10, .25, .35, .50)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
# Chunk 11
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
# Chunk 12
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
# Chunk 13
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
# Chunk 14
set.seed(9850)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .15,
cost = .01,
trControl = ctrl)
# Chunk 15
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
# Chunk 16
confusionMatrix(predictedClasses, reference = testData$binary_label)
# Chunk 17
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
# Chunk 18
pred <- predictedProbs[,2]
area <- auc(testData$binary_label, pred)
# Chunk 19
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
# Chunk 4
df1 <- df1[,-1]
# Chunk 5
set.seed(9850)
# Chunk 6
gp <- runif(nrow(df1))
# Chunk 7
df1 <- df1[order(gp),]
# Chunk 8
n = nrow(df1)
train = sample(1:n, size = round(0.75*n), replace=FALSE)
df1.train = df1[train,]
df1.test = df1[-train,]
# Chunk 9
tree <- ctree(factor(binary_label) ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.train)
# Chunk 10
plot(tree)
# Chunk 11
df1.test$prediction <- predict(tree, df1.test)
# Chunk 12
c2.tree <- rpart(prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.test)
printcp(c2.tree)
rpart(formula = prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data = df1.test, method = "class")
# Chunk 13
confusionMatrix(df1.test$prediction, df1.test$binary_label)
# Chunk 14
tree_confusion <- as.data.frame(table(df1.test$binary_label, df1.test$prediction))
tree_plot <- ggplot(tree_confusion)
tree_plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "Decision Tree Confusion Matrix") + geom_text(data = tree_confusion, aes(x=Var1, y=Var2, label=Freq), color = "white")
# Chunk 15
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
# Chunk 16
pred1 <- pred[,2]
# Chunk 17
area <- auc(df1.test$binary_label, pred1)
# Chunk 18
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(rpart)
library(class)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
# Chunk 4
df1 <- df1[,-c(1,3)]
# Chunk 5
set.seed(9850)
# Chunk 6
gp <- runif(nrow(df1))
# Chunk 7
df1_KNN <- df1[order(gp),]
# Chunk 8
normalize <- function(x){
return( (x - min(x)) / (max(x) - min(x)))}
# Chunk 9
df1_KNN_n <- as.data.frame(lapply(df1_KNN[,c(2,3,4,5,6,7,8,9,10)], normalize))
# Chunk 10
df1_KNN_train <- df1_KNN_n[1:552, ]
df1_KNN_test <- df1_KNN_n[553:735, ]
df1_KNN_train_target <- df1_KNN[1:552, 12]
df1_KNN_test_target <- df1_KNN[553:735, 12]
# Chunk 11
m1 <- knn(train = df1_KNN_train, test = df1_KNN_test, cl = df1_KNN_train_target, k=11, prob = TRUE)
# Chunk 12
confusionMatrix(m1, df1_KNN_test_target)
# Chunk 13
knn_confusion <- as.data.frame(table(df1_KNN_test_target, m1))
knn_plot <- ggplot(knn_confusion)
knn_plot + geom_tile(aes(x=df1_KNN_test_target, y=m1, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "KNN Confusion Matrix") + geom_text(data = knn_confusion, aes(x=df1_KNN_test_target, y=m1, label=Freq), color = "white")
# Chunk 14
knn_prob <- attr(m1, "prob")
# Chunk 15
prob <- 2*ifelse(m1 == "-1", 1-knn_prob, knn_prob) - 1
# Chunk 16
pred_knn <- prediction(knn_prob, df1_KNN_test_target)
# Chunk 17
pred_knn <- performance(pred_knn, "tpr", "fpr")
# Chunk 18
area <- auc(df1_KNN_test_target, knn_prob)
# Chunk 19
rocplot <- function(knn_prob, df1_KNN_test_target, ...) {
predob = prediction(knn_prob, df1_KNN_test_target)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(knn_prob, df1_KNN_test_target, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
# Chunk 4
df1 <- df1[,-c(1,2,3,13)]
# Chunk 5
gp <- runif(nrow(df1))
# Chunk 6
df1 <- df1[order(gp),]
# Chunk 7
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
# Chunk 8
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
# Chunk 9
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Chunk 10
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .15, 0.30),
C = c(0.01, 0.10, .25, .35, .50)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
# Chunk 11
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
# Chunk 12
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
# Chunk 13
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
# Chunk 14
set.seed(9850)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .15,
cost = .01,
trControl = ctrl)
# Chunk 15
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
# Chunk 16
confusionMatrix(predictedClasses, reference = testData$binary_label)
# Chunk 17
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
# Chunk 18
pred <- predictedProbs[,2]
area <- auc(testData$binary_label, pred)
# Chunk 19
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
# Chunk 4
df1 <- df1[,-c(1,2,3,13)]
# Chunk 5
gp <- runif(nrow(df1))
# Chunk 6
df1 <- df1[order(gp),]
# Chunk 7
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
# Chunk 8
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
# Chunk 9
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Chunk 10
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .15, 0.30),
C = c(0.01, 0.10, .25, .35, .50)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
# Chunk 11
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
# Chunk 12
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
# Chunk 13
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
# Chunk 14
set.seed(9850)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .15,
cost = .01,
trControl = ctrl)
# Chunk 15
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
# Chunk 16
confusionMatrix(predictedClasses, reference = testData$binary_label)
# Chunk 17
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
# Chunk 18
pred <- predictedProbs[,2]
area <- auc(testData$binary_label, pred)
# Chunk 19
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
bwplot(rValues,metric="ROC",ylab =c("Linear Kernal", "Radial Kernel"))
plot(svmFit)
plot(svmFit, testData)
plot(svm.tune2)
plot(svm.tune)
plot(svmFit, data=testData)
kernlab::plot(svmFit, data=testData)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
plot(svm.tune)
