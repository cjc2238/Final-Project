View(df1)
df1 <- df1[,-c(1,2,3,13)]
View(df1)
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(1:10)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
grid <- expand.grid(sigma = c(0, 2, 5),
C = c(0.25, 4, 8, 32, 64)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl
tune=grid)
grid <- expand.grid(sigma = c(0, 2, 5),
C = c(0.25, 4, 8, 32, 64)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl,
tuneGrid=grid)
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.15, .17, 0.19),
C = c(0.75, 0.9, 1, 1.1, 1.25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
grid <- expand.grid(sigma = c(0, 2, 5),
C = c(0.25, 4, 8, 32, 64))
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
View(trainX)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Data Manipulation")
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(1:10)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
set.seed(9850)
ctrl <- trainControl(method="svmRadial",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.15, .17, 0.19),
C = c(0.75, 0.9, 1, 1.1, 1.25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
View(testData)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
View(trainX)
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .5, 0.1),
C = c(0.01, 0.10, .15, .20, .25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
grid <- expand.grid(sigma = c(0, .1, 0.2),
C = c(0, 0.01, .1, .2, .21))
svmFit <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
tuneGrid = grid,
trControl = ctrl)
svmFit <- train(binary_label.~,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
trControl = ctrl)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
trControl = ctrl)
plot(svmFit)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .1,
cost = .01,
trControl = ctrl)
plot(svmFit)
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
confusionMatrix(predictedClasses, reference = testData$binary_label)
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
SVM_ROC <- plot(pred_svm, avg= "threshold", colorize=T, lwd=3, main="SVM Binary Label ROC Curve")
SVM_ROC <- plot(pred_svm, avg= "threshold", lwd=3, main="SVM Binary Label ROC Curve")
SVM_ROC <- plot(pred_svm, avg= "threshold", colorize=T, lwd=3, main="SVM Binary Label ROC Curve")
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1 <- df1[,-1]
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1 <- df1[,-1]
set.seed(9850)
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
n = nrow(df1)
train = sample(1:n, size = round(0.75*n), replace=FALSE)
df1.train = df1[train,]
df1.test = df1[-train,]
tree <- ctree(factor(binary_label) ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.train)
plot(tree)
df1.test$prediction <- predict(tree, df1.test)
c2.tree <- rpart(prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.test)
printcp(c2.tree)
rpart(formula = prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data = df1.test, method = "class")
confusionMatrix(df1.test$prediction, df1.test$binary_label)
plot(confusionMatrix(df1.test$prediction, df1.test$binary_label))
tree_confusion <- as.data.frame(table(df1.test$binary_label, df1.test$prediction))
tree_plot <- ggplot(tree_confusion)
tree_plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "Decision Tree Confusion Matrix") + geom_text(data = tree_confusion, aes(x=Var1, y=Var2, label=Freq), color = "white")
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
roc_pred <- prediction(pred[,1], df1.test$binary_label)
TREE_ROC <- plot(performance(roc_pred, measure="tpr", x.measure="fpr"), colorize=TRUE, main="Tree Binary Label ROC Curve", lwd=3, avg= "threshold")
list(probs)
summary(pred)
plot(pred)
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
roc_pred <- prediction(pred[,2], df1.test$binary_label)
TREE_ROC <- plot(performance(roc_pred, measure="tpr", x.measure="fpr"), colorize=TRUE, main="Tree Binary Label ROC Curve", lwd=3, avg= "threshold")
confusionMatrix(df1.test$prediction, df1.test$binary_label)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Data Manipulation")
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .5, 0.1),
C = c(0.01, 0.10, .15, .20, .25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .1,
cost = .01,
trControl = ctrl)
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
confusionMatrix(predictedClasses, reference = testData$binary_label)
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
SVM_ROC <- plot(pred_svm, avg= "threshold", colorize=T, lwd=3, main="SVM Binary Label ROC Curve")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(rpart)
library(class)
library(ROCR)
library(caret)
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1 <- df1[,-c(1,3)]
set.seed(9850)
gp <- runif(nrow(df1))
df1_KNN <- df1[order(gp),]
normalize <- function(x){
return( (x - min(x)) / (max(x) - min(x)))}
df1_KNN_n <- as.data.frame(lapply(df1_KNN[,c(2,3,4,5,6,7,8,9,10)], normalize))
df1_KNN_train <- df1_KNN_n[1:552, ]
df1_KNN_test <- df1_KNN_n[553:735, ]
df1_KNN_train_target <- df1_KNN[1:552, 12]
df1_KNN_test_target <- df1_KNN[553:735, 12]
m1 <- knn(train = df1_KNN_train, test = df1_KNN_test, cl = df1_KNN_train_target, k=27, prob = TRUE)
confusionMatrix(m1, df1_KNN_test_target)
knn_confusion <- as.data.frame(table(df1_KNN_test_target, m1))
knn_plot <- ggplot(knn_confusion)
knn_plot + geom_tile(aes(x=df1_KNN_test_target, y=m1, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "KNN Confusion Matrix") + geom_text(data = knn_confusion, aes(x=df1_KNN_test_target, y=m1, label=Freq), color = "white")
knn_prob <- attr(m1, "prob")
prob <- 2*ifelse(m1 == "-1", 1-knn_prob, knn_prob) - 1
pred_knn <- performance(pred_knn, "tpr", "fpr")
pred_knn <- prediction(knn_prob, df1_KNN_test_target)
pred_knn <- performance(pred_knn, "tpr", "fpr")
KNN_ROC <- plot(pred_knn, avg= "threshold", colorize=T, lwd=3, main="KNN Binary Label ROC Curve")
install.packages("devtools")
devtools::install_github("google/CausalImpact")
devtools::install_github("google/CausalImpact")
devtools::install_github("google/CausalImpact")
devtools::install_github("google/CausalImpact")
devtools::install_github("google/CausalImpact")
devtools::install_github("google/CausalImpact")
install.packages("BoomSpikeSlab")
devtools::install_github("google/CausalImpact")
install.packages("xts")
devtools::install_github("google/CausalImpact")
library(CausalImpact)
?grep
