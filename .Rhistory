perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred[,2], df1.test, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
rocplot <- function(pred, df1.test, ...) {
predob = prediction(pred[,2], df1.test)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred[,2], df1.test, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
pred1 <- pred[,1]
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
area <- auc(df1.test$prediction, pred1)
rocplot <- function(pred1, df1.test$prediction, ...) {
predob = prediction(pred1, df1.test)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
area <- auc(df1.test$prediction, pred1)
area <- auc(df1.test$prediction, pred1)
pred1 <- pred[,2]
area <- auc(df1.test$prediction, pred1)
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
roc_pred <- prediction(pred[,2], df1.test$binary_label)
TREE_ROC <- plot(performance(roc_pred, measure="tpr", x.measure="fpr"), colorize=TRUE, main="Decision Tree ROC Curve", lwd=3, avg= "threshold")
area <- auc(df1.test$prediction, pred1)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1 <- df1[,-1]
set.seed(9850)
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
n = nrow(df1)
train = sample(1:n, size = round(0.75*n), replace=FALSE)
df1.train = df1[train,]
df1.test = df1[-train,]
tree <- ctree(factor(binary_label) ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.train)
plot(tree)
df1.test$prediction <- predict(tree, df1.test)
c2.tree <- rpart(prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.test)
printcp(c2.tree)
rpart(formula = prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data = df1.test, method = "class")
confusionMatrix(df1.test$prediction, df1.test$binary_label)
tree_confusion <- as.data.frame(table(df1.test$binary_label, df1.test$prediction))
tree_plot <- ggplot(tree_confusion)
tree_plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "Decision Tree Confusion Matrix") + geom_text(data = tree_confusion, aes(x=Var1, y=Var2, label=Freq), color = "white")
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
roc_pred <- prediction(pred[,2], df1.test$binary_label)
TREE_ROC <- plot(performance(roc_pred, measure="tpr", x.measure="fpr"), colorize=TRUE, main="Decision Tree ROC Curve", lwd=3, avg= "threshold")
pred1 <- pred[,2]
area <- auc(df1.test$prediction, pred1)
View(df1.test)
area <- auc(df1.test, pred1)
area <- auc(df1.test$binary_label, pred1)
rocplot <- function(pred1, df1.test$binary_label, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="k-Nearest Neighbors ROC Curve")
rocplot <- function(pred1, df1.test$binary_label, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
rocplot <- function(pred1, df1.test$binary_label, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
area <- auc(df1.test$binary_label, pred1)
rocplot <- function(pred1, df1.test$binary_label, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
rocplot <- function(pred1, df1.test$binary_label, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
area <- auc(df1.test$binary_label, pred1)
area <- auc(df1.test$binary_label, pred1)
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
# Chunk 4
df1 <- df1[,-1]
# Chunk 5
set.seed(9850)
# Chunk 6
gp <- runif(nrow(df1))
# Chunk 7
df1 <- df1[order(gp),]
# Chunk 8
n = nrow(df1)
train = sample(1:n, size = round(0.75*n), replace=FALSE)
df1.train = df1[train,]
df1.test = df1[-train,]
# Chunk 9
tree <- ctree(factor(binary_label) ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.train)
# Chunk 10
plot(tree)
# Chunk 11
df1.test$prediction <- predict(tree, df1.test)
# Chunk 12
c2.tree <- rpart(prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.test)
printcp(c2.tree)
rpart(formula = prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data = df1.test, method = "class")
# Chunk 13
confusionMatrix(df1.test$prediction, df1.test$binary_label)
# Chunk 14
tree_confusion <- as.data.frame(table(df1.test$binary_label, df1.test$prediction))
tree_plot <- ggplot(tree_confusion)
tree_plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "Decision Tree Confusion Matrix") + geom_text(data = tree_confusion, aes(x=Var1, y=Var2, label=Freq), color = "white")
# Chunk 15
pred1 <- pred[,2]
# Chunk 16
area <- auc(df1.test$binary_label, pred1)
# Chunk 17
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
# Chunk 4
df1 <- df1[,-1]
# Chunk 5
set.seed(9850)
# Chunk 6
gp <- runif(nrow(df1))
# Chunk 7
df1 <- df1[order(gp),]
# Chunk 8
n = nrow(df1)
train = sample(1:n, size = round(0.75*n), replace=FALSE)
df1.train = df1[train,]
df1.test = df1[-train,]
# Chunk 9
tree <- ctree(factor(binary_label) ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.train)
# Chunk 10
plot(tree)
# Chunk 11
df1.test$prediction <- predict(tree, df1.test)
# Chunk 12
c2.tree <- rpart(prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.test)
printcp(c2.tree)
rpart(formula = prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data = df1.test, method = "class")
# Chunk 13
confusionMatrix(df1.test$prediction, df1.test$binary_label)
# Chunk 14
tree_confusion <- as.data.frame(table(df1.test$binary_label, df1.test$prediction))
tree_plot <- ggplot(tree_confusion)
tree_plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "Decision Tree Confusion Matrix") + geom_text(data = tree_confusion, aes(x=Var1, y=Var2, label=Freq), color = "white")
# Chunk 15
pred1 <- pred[,2]
# Chunk 16
area <- auc(df1.test$binary_label, pred1)
# Chunk 17
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
pred1 <- pred[,2]
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(ggplot2)
library(party)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
# Chunk 3
df1 <- read.csv("AAA_Data_Binary_Label.csv")
# Chunk 4
df1 <- df1[,-1]
# Chunk 5
set.seed(9850)
# Chunk 6
gp <- runif(nrow(df1))
# Chunk 7
df1 <- df1[order(gp),]
# Chunk 8
n = nrow(df1)
train = sample(1:n, size = round(0.75*n), replace=FALSE)
df1.train = df1[train,]
df1.test = df1[-train,]
# Chunk 9
tree <- ctree(factor(binary_label) ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.train)
# Chunk 10
plot(tree)
# Chunk 11
df1.test$prediction <- predict(tree, df1.test)
# Chunk 12
c2.tree <- rpart(prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data=df1.test)
printcp(c2.tree)
rpart(formula = prediction ~ homepage + forumng + glossary + dataplus + oucollaborate + oucontent + resource + subpage + url, data = df1.test, method = "class")
# Chunk 13
confusionMatrix(df1.test$prediction, df1.test$binary_label)
# Chunk 14
tree_confusion <- as.data.frame(table(df1.test$binary_label, df1.test$prediction))
tree_plot <- ggplot(tree_confusion)
tree_plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq), color = "gray") + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(high = "red") + labs(fill="Frequency", title = "Decision Tree Confusion Matrix") + geom_text(data = tree_confusion, aes(x=Var1, y=Var2, label=Freq), color = "white")
# Chunk 15
pred <- predict(tree, newdata=df1.test)
probs <- treeresponse(tree, newdata=df1.test)
pred <- do.call(rbind, probs)
summary(pred)
# Chunk 16
pred1 <- pred[,2]
# Chunk 17
area <- auc(df1.test$binary_label, pred1)
# Chunk 18
rocplot <- function(pred1, df1.test, ...) {
predob = prediction(pred1, df1.test$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred1, df1.test, col="black", avg= "threshold", lwd=2, main="Decision Tree ROC Curve")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
View(df1)
df1 <- df1[,-c(1,2,3,13)]
df1 <- df1[,-c(1,2,3,13)]
df1 <- df1[,-c(1,2,3,13)]
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
df1 <- read.csv("AAA_Data_Binary_Label.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
library(pROC)
setwd("~/GitHub/Final-Project/Three Models with Only Click Data Features [Binary Label]")
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .15, 0.30),
C = c(0.01, 0.10, .25, .35, .50)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .15, 0.30),
C = c(0.01, 0.10, .25, .35, .50)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .15,
cost = .01,
trControl = ctrl)
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
confusionMatrix(predictedClasses, reference = testData$binary_label)
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
svm_area <- auc(testData$predictedClasses, prob)
SVM_ROC <- plot(pred_svm, avg= "threshold", colorize=T, lwd=3, main="Support Vector Machine ROC Curve")
View(predictedProbs)
svm_area <- auc(testData$binary_label, predictedProbs[,1])
svm_area <- auc(testData$binary_label, predictedProbs[,2])
svm_area <- auc(testData$binary_label, predictedProbs[,1])
pred <- predictedProbs[,1]
svm_area <- auc(testData$binary_label, pred)
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(knn_prob, df1_KNN_test_target, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData$binary_label, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
pred <- predictedProbs[,1]
area <- auc(testData$binary_label, pred)
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
pred <- predictedProbs[,2]
area <- auc(testData$binary_label, pred)
rocplot <- function(pred, testData, ...) {
predob = prediction(pred, testData$binary_label)
perf = performance(predob, "tpr", "fpr")
plot(perf, ...)
area <- format(round(area, 4), nsmall = 4)
text(x=0.8, y=0.1, labels = paste("AUC =", area))
segments(x0=0, y0=0, x1=1, y1=1, col="black", lty=2)
}
rocplot(pred, testData, col="black", avg= "threshold", lwd=2, main="Support Vector Machine ROC Curve")
