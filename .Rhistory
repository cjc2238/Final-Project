click_df_2013j_aaa_df6 <- tidyr::spread(click_df_2013j_aaa_df5, week, 'sum_clicks')
View(click_df_2013j_aaa_df6)
click_df_2013j_aaa_df5$sum_clicks[is.na(click_df_2013j_aaa_df5$sum_clicks)] <- 0
click_df_2013j_aaa_df6 <- tidyr::spread(click_df_2013j_aaa_df5, week, 'sum_clicks')
click_df_2013j_aaa_df6 <- tidyr::spread(click_df_2013j_aaa_df5, week, 'sum_clicks')
click_df <- merge(std_vle_df, vle_df, by= c("id_site","code_presentation","code_module"))
click_df_2013j_aaa <- subset(click_df, code_module %in% "AAA" & code_presentation %in% "2013J", select = c(id_student, date, sum_click, activity_type))
click_df_2013j_aaa_df3 <- click_df_2013j_aaa %>% dplyr::group_by(bins, activity_type, id_student) %>% dplyr::summarise(sum(sum_click))
click_df_2013j_aaa$bins <- cut(click_df_2013j_aaa$date, breaks = seq(-1, 268, 7))
click_df_2013j_aaa$bins = as.numeric(click_df_2013j_aaa$bins)
click_df_2013j_aaa_df3 <- click_df_2013j_aaa %>% dplyr::group_by(bins, activity_type, id_student) %>% dplyr::summarise(sum(sum_click))
click_df_2013j_aaa_df4 <- tidyr::spread(click_df_2013j_aaa_df3, activity_type, 'sum(sum_click)')
click_df_2013j_aaa_df4$total_weekly_clicks <- rowSums(click_df_2013j_aaa_df4[,c("dataplus","forumng","glossary","homepage","oucollaborate","oucontent","resource","subpage","url")], na.rm=T)
click_df_2013j_aaa_df5 <- data.frame(click_df_2013j_aaa_df4$id_student, click_df_2013j_aaa_df4$bins, click_df_2013j_aaa_df4$total_weekly_clicks)
names(click_df_2013j_aaa_df5) <- c("student_id","week","sum_clicks")
###############################
## Replace N/A Values with 0 ##
###############################
click_df_2013j_aaa_df5$week[is.na(click_df_2013j_aaa_df5$week)] <- 0
click_df_2013j_aaa_df5$sum_clicks[is.na(click_df_2013j_aaa_df5$sum_clicks)] <- 0
###############################
## Create Data Frame For ML ###
###############################
click_df_2013j_aaa_df6 <- tidyr::spread(click_df_2013j_aaa_df5, week, 'sum_clicks')
View(click_df_2013j_aaa_df6)
View(assessments_df)
View(std_assessments_df)
View(click_df_2013j_aaa_df6)
View(click_df_2013j_aaa_df5)
View(assessments_df)
View(std_assessments_df)
2013j_aaa_final_examscores <- subset(std_assessments_df, id_assessment %in% "1757", select = c(score, id_student))
final_exam_scores_2013j_aaa <- subset(std_assessments_df, id_assessment %in% "1757", select = c(score, id_student))
View(final_exam_scores_2013j_aaa)
final_exam_scores_2013j_aaa <- subset(std_assessments_df, id_assessment %in% "1763", select = c(score, id_student))
View(final_exam_scores_2013j_aaa)
View(std_info_df)
View(std_info_df)
final_result_2013j_aaa <- subset(std_assessments_df, code_presentation %in% "2013J" & code_module %in% "AAA", select = c(id_student, final_result))
final_result_2013j_aaa <- subset(std_info_df, code_presentation %in% "2013J" & code_module %in% "AAA", select = c(id_student, final_result))
View(final_result_2013j_aaa)
names(final_result_2013j_aaa) <- c("student_id","final_result")
View(final_result_2013j_aaa)
View(click_df_2013j_aaa_df3)
View(click_df_2013j_aaa_df6)
click_df_2013j_aaa_df7 <- merge(final_result_2013j_aaa, click_df_2013j_aaa_df6 , by= c("student_id"))
View(click_df_2013j_aaa_df7)
click_df_2013j_aaa_df7 <- merge( click_df_2013j_aaa_df6, final_result_2013j_aaa, by= c("student_id"))
write.csv(click_df_2013j_aaa_df7, file = "2013_AAA_Click_Data.csv")
library(tidyr)
library(dplyr)
source('~/GitHub/Final-Project/Data Manipulation/Load Data Frames from CSV Files.R', echo=TRUE)
click_df <- merge(std_vle_df, vle_df, by= c("id_site","code_presentation","code_module"))
df <- split(click_df, list(click_df$code_presentation,click_df$code_module), drop = TRUE)
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Data Manipulation")
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
View(df1)
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(7:11)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(7:11)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(7:11)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(1:10)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
setwd("~/GitHub/Final-Project/Data Manipulation")
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(1:10)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Data Manipulation")
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
View(df1)
df1 <- df1[,-c(1,2,3,13)]
View(df1)
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(1:10)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
grid <- expand.grid(sigma = c(0, 2, 5),
C = c(0.25, 4, 8, 32, 64)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl
tune=grid)
grid <- expand.grid(sigma = c(0, 2, 5),
C = c(0.25, 4, 8, 32, 64)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl,
tuneGrid=grid)
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.15, .17, 0.19),
C = c(0.75, 0.9, 1, 1.1, 1.25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
grid <- expand.grid(sigma = c(0, 2, 5),
C = c(0.25, 4, 8, 32, 64))
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
View(trainX)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
library(ggplot2)
library(kernlab)
library(rpart)
library(ROCR)
library(caret)
setwd("~/GitHub/Final-Project/Data Manipulation")
df1 <- read.csv("AAA_Data_for_Tree.csv")
df1$binary_label <- as.character(df1$binary_label)
df1$binary_label[df1$binary_label == " Monitor"] <- "monitor"
df1$binary_label[df1$binary_label == "Don't Monitor"] <- "ignore"
df1$binary_label <- as.factor(df1$binary_label)
df1 <- df1[,-c(1,2,3,13)]
gp <- runif(nrow(df1))
df1 <- df1[order(gp),]
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,c(1:10)]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
set.seed(9850)
ctrl <- trainControl(method="svmRadial",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.15, .17, 0.19),
C = c(0.75, 0.9, 1, 1.1, 1.25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
View(testData)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
trainIndex <- createDataPartition(df1$binary_label,p=.75,list=FALSE)
trainData <- df1[trainIndex,]
testData  <- df1[-trainIndex,]
trainX <-trainData[,-10]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data
View(trainX)
set.seed(9850)
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
repeats=5,		    # do 5 repititions of cv
summaryFunction=twoClassSummary,	# Use AUC to pick the best model
classProbs=TRUE)
set.seed(9850)
svm.tune <- caret::train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",   # Radial kernel
tuneLength = 9,					# 9 values of the cost function
preProc = c("center","scale"),  # Center and scale data
metric="ROC",
trControl=ctrl)
svm.tune
# Second pass
# Look at the results of svm.tune and refine the parameter space
set.seed(9850)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.0, .5, 0.1),
C = c(0.01, 0.10, .15, .20, .25)
)
#Train and Tune the SVM
svm.tune <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center","scale"),
metric="ROC",
tuneGrid = grid,
trControl=ctrl)
svm.tune
#Linear Kernel
set.seed(9850)
#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
y= trainData$binary_label,
method = "svmLinear",
preProc = c("center","scale"),
metric="ROC",
trControl=ctrl)
svm.tune2
rValues <- resamples(list(svm=svm.tune,svm.tune2))
rValues$values
summary(rValues)
bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))
grid <- expand.grid(sigma = c(0, .1, 0.2),
C = c(0, 0.01, .1, .2, .21))
svmFit <- train(x=trainX,
y= trainData$binary_label,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
tuneGrid = grid,
trControl = ctrl)
svmFit <- train(binary_label.~,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
trControl = ctrl)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
trControl = ctrl)
plot(svmFit)
svmFit <- train(binary_label~.,
data= trainData,
method = "svmRadial",
preProc = c("center", "scale"),
metric="ROC",
sigma = .1,
cost = .01,
trControl = ctrl)
plot(svmFit)
testData$predictedClasses <- predict(svmFit, testData, prob= TRUE)
predictedClasses <- predict(svmFit, testData )
predictedProbs <- predict(svmFit, newdata = testData , type = "prob")
confusionMatrix(predictedClasses, reference = testData$binary_label)
pred_svm <- ROCR::prediction(predictedProbs$monitor, testData$binary_label)
pred_svm <- performance(pred_svm, "tpr", "fpr")
SVM_ROC <- plot(pred_svm, avg= "threshold", colorize=T, lwd=3, main="SVM Binary Label ROC Curve")
SVM_ROC <- plot(pred_svm, avg= "threshold", lwd=3, main="SVM Binary Label ROC Curve")
SVM_ROC <- plot(pred_svm, avg= "threshold", colorize=T, lwd=3, main="SVM Binary Label ROC Curve")
